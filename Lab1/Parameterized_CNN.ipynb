{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMGXvf28rsKUSIlugZjnK2/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuxTu/HW_Arch_of_DL/blob/main/Lab1/Parameterized_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%xterm"
      ],
      "metadata": {
        "id": "_Ng9iM-qOIXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, n_conv, n_fc, conv_ch, filter_size, fc_size, pooling_size, input_size, input_channels, n_classes, activation_fn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        fc_input_size = input_size\n",
        "\n",
        "        self.pooling_size = pooling_size\n",
        "        if(pooling_size > 1):\n",
        "            self.has_pooling = True\n",
        "        else:\n",
        "            self.has_pooling = False\n",
        "\n",
        "        for i in range(n_conv):\n",
        "            if(i == 0):\n",
        "                input_channel = input_channels\n",
        "            else:\n",
        "                input_channel = conv_ch[i-1]\n",
        "            conv_layer = nn.Conv2d(input_channel, conv_ch[i], filter_size[i])\n",
        "            self.conv_layers.append(conv_layer)\n",
        "            fc_input_size = fc_input_size - filter_size[i] + 1\n",
        "            if(self.has_pooling):\n",
        "                fc_input_size = (fc_input_size // pooling_size) if (fc_input_size % pooling_size == 0) else (fc_input_size // pooling_size + 1)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        fc_input_size = conv_ch[-1] * fc_input_size * fc_input_size\n",
        "        self.fc_layers.append(nn.Linear(fc_input_size, fc_size[0]))\n",
        "        for i in range(1, n_fc-1):\n",
        "            fc_layer = nn.Linear(fc_size[i-1], fc_size[i])\n",
        "            self.fc_layers.append(fc_layer)\n",
        "\n",
        "        self.output_layer = nn.Linear(fc_size[-1], n_classes)\n",
        "        self.activation_fn = activation_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv in self.conv_layers:\n",
        "            x = self.activation_fn(conv(x))\n",
        "            # print(f\"After conv the shape of x is: {x.shape}\")\n",
        "            if(self.has_pooling):\n",
        "                pooling = nn.MaxPool2d(self.pooling_size, self.pooling_size, padding=x.shape[-1]%self.pooling_size)\n",
        "                x = pooling(x)\n",
        "            # print(f\"After pooling the shape of x is: {x.shape}\")\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # print(f\"After flatten the shape of x is: {x.shape}\")\n",
        "\n",
        "        for fc in self.fc_layers:\n",
        "            x = self.activation_fn(fc(x))\n",
        "\n",
        "        return self.output_layer(x)\n",
        "\n",
        "def train(model_params, model_name, device, epochs):\n",
        "    model_path = MODEL_PATH + model_name + '.pth'\n",
        "    net = ConvNet(**model_params)\n",
        "\n",
        "    # load model state\n",
        "    try:\n",
        "        net.load_state_dict(torch.load(model_path))\n",
        "        print(\"Model state loaded successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "        print(f\"No saved model state found at '{model_path}'.\")\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    # load record\n",
        "    record_path = RECORD_PATH + model_name + '.json'\n",
        "    try:\n",
        "        with open(record_path, 'r') as file:\n",
        "            record = json.load(file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        os.makedirs(RECORD_PATH, exist_ok=True)\n",
        "        record = {\"name\": model_name, \"epochs\": 0, \"training_records\": []}\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0\n",
        "                # torch.save(net.state_dict(), PATH)\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    # save current epochs\n",
        "    record[\"epochs\"] = record[\"epochs\"] + epochs\n",
        "\n",
        "    # save model\n",
        "    torch.save(net.state_dict(), model_path)\n",
        "\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            # collect the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "    test_result = {}\n",
        "\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "        test_result[classname] = accuracy\n",
        "\n",
        "    record[\"training_records\"].append({\"training_epoch\": record[\"epochs\"], \"accuracy\": test_result})\n",
        "\n",
        "    with open(record_path, 'w+') as file:\n",
        "        json.dump(record, file, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_PATH = './model_CIFAR10_10iters/'\n",
        "    RECORD_PATH = './records_CIFAR10_10iters/'\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    batch_size = 4\n",
        "    # Load trainset\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Load testset\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    conv_params_original = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c1_8 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [8, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c1_10 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [10, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c1_12 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [12, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c3_20 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 20], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c3_24 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 24], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_c3_28 = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 28], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_9_layers = {'n_conv': 3, 'n_fc': 3, 'conv_ch': [6, 16, 26], 'filter_size': [5, 5, 2], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_11_layers = {'n_conv': 4, 'n_fc': 3, 'conv_ch': [6, 16, 26, 36], 'filter_size': [2, 2, 2, 2], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_13_layers = {'n_conv': 5, 'n_fc': 3, 'conv_ch': [6, 16, 26, 36, 50], 'filter_size': [2, 2, 2, 2, 2], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.relu}\n",
        "\n",
        "    conv_params_sigmoid = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.sigmoid}\n",
        "\n",
        "    conv_params_tanh = {'n_conv': 2, 'n_fc': 3, 'conv_ch': [6, 16], 'filter_size': [5, 5], 'fc_size': [120, 84], 'pooling_size': 2, 'input_size': trainset[0][0].shape[2], 'input_channels': 3, 'n_classes': len(classes), 'activation_fn': F.tanh}\n",
        "\n",
        "    models_params = [conv_params_original, conv_params_c1_8, conv_params_c1_10, conv_params_c1_12, conv_params_c3_20, conv_params_c3_24, conv_params_c3_28, conv_params_9_layers, conv_params_11_layers, conv_params_13_layers, conv_params_sigmoid, conv_params_tanh]\n",
        "\n",
        "    models_names = [\"conv_params_original\", \"conv_params_c1_8\", \"conv_params_c1_10\", \"conv_params_c1_12\", \"conv_params_c3_20\", \"conv_params_c3_24\", \"conv_params_c3_28\", \"conv_params_9_layers\", \"conv_params_11_layers\", \"conv_params_13_layers\", \"conv_params_sigmoid\", \"conv_params_tanh\"]\n",
        "\n",
        "    for i in range(10):\n",
        "      for param, name in zip(models_params, models_names):\n",
        "          print(\"Model <\"+name+\"> starts training\")\n",
        "          train(param, name, device, 1)\n",
        "          print(\"Model <\"+name+\"> finishes training\")\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r \"./model_CIFAR10_10iters\" \"/content/drive/MyDrive\"\n",
        "# !cp -r \"./records_CIFAR10_10iters\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "eXEZyIe3Dxk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}